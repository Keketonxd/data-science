### Методы сбора и обработки данных из сети Интернет

#### _Урок 1. Основы клиент-серверного взаимодействия. Парсинг API_
1. Посмотреть документацию к API GitHub, разобраться как вывести список репозиториев для конкретного пользователя, сохранить JSON-вывод в файле *.json.
2. Изучить список открытых API. Найти среди них любое, требующее авторизацию (любого типа). Выполнить запросы к нему, пройдя авторизацию. Ответ сервера записать в файл.

#### _Урок 2. Парсинг HTML. BeautifulSoup, MongoDB_

1. Необходимо собрать информацию по продуктам питания с сайта: https://roscontrol.com/category/produkti/#popup. Приложение должно анализировать несколько страниц сайта (вводим через input или аргументы).
Получившийся список должен содержать:

- Наименование продукта.
- Все параметры (Безопасность, Натуральность, Пищевая ценность, Качество)
- Общую оценку
- Сайт, откуда получена информация.

Общий результат можно вывести с помощью dataFrame через Pandas. Сохраните в json либо csv.

#### _Урок 3. Системы управления базами данных MongoDB и SQLite в Python_

1. Развернуть у себя на компьютере/виртуальной машине/хостинге MongoDB и реализовать функцию, записывающую собранные вакансии в созданную БД.
2. Написать функцию, которая производит поиск и выводит на экран вакансии с заработной платой больше введённой суммы. (Для тех, кто делал росконтроль, вывести продукты с рейтингом выше, либо равным, чем введённый)
3. Написать функцию, которая будет добавлять в вашу базу данных только новые вакансии с сайта.
